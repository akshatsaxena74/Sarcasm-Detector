{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding, Lambda, LSTM, Dense, Dropout, Concatenate, Attention\n",
    "\n",
    "class TextFeature:\n",
    "    def __init__(self, vocab_size, embedding_dim, seq_len, hidden_size, fusion_dim, dropout_rate, embedding_matrix):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fusion_dim = fusion_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "\n",
    "    def model_create(self, fusion_vector):\n",
    "        text_input = Input(shape=(self.seq_len,), name='text_input')\n",
    "        embedding_layer = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, weights=[self.embedding_matrix], input_length=self.seq_len, trainable=False)(text_input)\n",
    "        fusion_input = tf.constant(fusion_vector, dtype=tf.float32, name='fusion_vector')\n",
    "        fusion_expanded = Lambda(lambda x: tf.expand_dims(x, axis=1))(fusion_input)\n",
    "        fusion_tiled = Lambda(lambda x: tf.tile(x, [1, self.seq_len, 1]))(fusion_expanded)\n",
    "        lstm_input = Concatenate(axis=-1)([embedding_layer, fusion_tiled])\n",
    "        lstm_forward = LSTM(self.hidden_size, return_sequences=True, dropout=self.dropout_rate)\n",
    "        lstm_backward = LSTM(self.hidden_size, return_sequences=True, dropout=self.dropout_rate, go_backwards=True)\n",
    "        out_fw = lstm_forward(lstm_input)\n",
    "        out_bw = lstm_backward(lstm_input)\n",
    "        lstm_out = Concatenate(axis=-1)([out_fw, out_bw])\n",
    "        attention = Attention()([lstm_out, lstm_out])\n",
    "        mean_vec = Lambda(lambda x: tf.reduce_mean(x, axis=1))(attention)\n",
    "        fused_vec = Dense(self.hidden_size, activation='relu')(mean_vec)\n",
    "        return Model(inputs=[text_input], outputs=[lstm_out, mean_vec, fused_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, vocab_file, vector_file):\n",
    "        self.vocab_file = vocab_file\n",
    "        self.vector_file = vector_file\n",
    "\n",
    "    def get_vocab(self):\n",
    "        with open(self.vocab_file, 'r') as f:\n",
    "            vocab = pickle.load(f)\n",
    "        return vocab\n",
    "\n",
    "    def load_embedding_matrix(self, vocab):\n",
    "        with open(self.vector_file, 'rb') as f:\n",
    "            first_line = f.readline()\n",
    "            embedding_dimension = len(first_line.split())  # include the word itself\n",
    "        embedding_matrix = np.zeros((len(vocab), embedding_dimension))\n",
    "        with open(self.vector_file, 'r') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                if word in vocab:\n",
    "                    embedding_matrix[vocab[word]] = vector\n",
    "        return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, vocab_file, vector_file):\n",
    "        self.vocab_file = vocab_file\n",
    "        self.vector_file = vector_file\n",
    "\n",
    "    def get_vocab(self):\n",
    "        vocab = {}\n",
    "        with open(self.vocab_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    word, index = parts\n",
    "                    vocab[word] = int(index)\n",
    "        return vocab\n",
    "\n",
    "    def load_embedding_matrix(self, vocab):\n",
    "        with open(self.vector_file, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            embedding_dimension = len(first_line.split())  # include the word itself\n",
    "        embedding_matrix = np.zeros((len(vocab), embedding_dimension))\n",
    "        with open(self.vector_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                if word in vocab:\n",
    "                    embedding_matrix[vocab[word]] = vector\n",
    "        return embedding_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, showing an example on how to compile the model with an example\n",
    "\n",
    "NOTE: For fusion vector, take a look at the flowchart shared on the group. In the attribute modality part of the model, you shall be getting a final fusion vector after concatenating the vectors you got from that part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">328</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">599,040</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">599,040</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ lambda_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m200\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m328\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m599,040\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m599,040\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_11 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ lambda_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,408</span> (5.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,329,408\u001b[0m (5.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,408</span> (5.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,329,408\u001b[0m (5.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_file_path = '/Users/akshatsrivastava/Downloads/vocab.txt'\n",
    "vector_file_path = '/Users/akshatsrivastava/Downloads/vector.txt'\n",
    "\n",
    "data_loader = DataLoader(vocab_file=vocab_file_path, vector_file=vector_file_path)\n",
    "vocab = data_loader.get_vocab()\n",
    "embedding_matrix = data_loader.load_embedding_matrix(vocab)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 200\n",
    "seq_len = 75\n",
    "hidden_size = 256\n",
    "fusion_dim = 128\n",
    "dropout_rate = 0.2\n",
    "\n",
    "dummy_fusion_vector = tf.random.uniform((1, fusion_dim))\n",
    "\n",
    "text_feature = TextFeature(vocab_size, embedding_dim, seq_len, hidden_size, fusion_dim, dropout_rate, embedding_matrix)\n",
    "model_with_input = text_feature.model_create(fusion_vector=dummy_fusion_vector)\n",
    "model_with_input.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[0.15271997, 0.43502796, 0.3780625 , 0.47857165, 0.4456017 ,\n",
       "        0.56018305, 0.58017147, 0.6445726 , 0.48586547, 0.62983954,\n",
       "        0.4075606 , 0.6657312 , 0.3207897 , 0.6257962 , 0.61284983,\n",
       "        0.68612003, 0.6839267 , 0.8543855 , 0.46688068, 0.9506557 ,\n",
       "        0.6016748 , 0.70467365, 0.251804  , 0.27099264, 0.1252563 ,\n",
       "        0.11441779, 0.2842698 , 0.01917946, 0.9990982 , 0.3985033 ,\n",
       "        0.2563609 , 0.9770006 , 0.9612322 , 0.79477966, 0.84978235,\n",
       "        0.93681073, 0.03004217, 0.97958815, 0.88094854, 0.8607477 ,\n",
       "        0.5723047 , 0.5640781 , 0.07415664, 0.9083953 , 0.60345066,\n",
       "        0.9472817 , 0.88929844, 0.31198025, 0.20118284, 0.7715012 ,\n",
       "        0.14483213, 0.02880359, 0.9133599 , 0.325096  , 0.5438969 ,\n",
       "        0.70141673, 0.38908815, 0.95163894, 0.22169352, 0.01865411,\n",
       "        0.55895126, 0.95328   , 0.4788072 , 0.35873008, 0.55451953,\n",
       "        0.5652684 , 0.35448194, 0.1492188 , 0.07788527, 0.9523579 ,\n",
       "        0.7950678 , 0.77141273, 0.6345997 , 0.6858927 , 0.26926947,\n",
       "        0.8000456 , 0.12573242, 0.5896306 , 0.5520148 , 0.5397912 ,\n",
       "        0.69496405, 0.61271036, 0.958004  , 0.78722954, 0.33885813,\n",
       "        0.3631785 , 0.65109074, 0.34811115, 0.4678079 , 0.01980686,\n",
       "        0.5837238 , 0.78442967, 0.18792868, 0.67222476, 0.7913016 ,\n",
       "        0.9329324 , 0.24676228, 0.20053184, 0.18376172, 0.3247664 ,\n",
       "        0.6760577 , 0.07606006, 0.48677707, 0.19291377, 0.74695563,\n",
       "        0.4900211 , 0.59001184, 0.8565068 , 0.22146738, 0.23048425,\n",
       "        0.46294332, 0.33637536, 0.40448904, 0.8213624 , 0.5857769 ,\n",
       "        0.76029515, 0.58410215, 0.53062665, 0.32618237, 0.18230236,\n",
       "        0.7481288 , 0.17629075, 0.83444047, 0.47753894, 0.01898134,\n",
       "        0.14891386, 0.61915004, 0.22864187]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_fusion_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
